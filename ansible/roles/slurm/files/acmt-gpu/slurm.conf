#
# Example slurm.conf file. Please run configurator.html
# (in doc/html) to build a configuration file customized
# for your environment.
#
#
# slurm.conf file generated by configurator.html.
#
# See the slurm.conf man page for more information.
#
ClusterName=hades
ControlMachine=hades01
ControlAddr=hades01
#BackupController=
#BackupAddr=
#
SlurmUser=slurm
#SlurmdUser=root
SlurmctldPort=6817
SlurmdPort=6818
AuthType=auth/munge
#JobCredentialPrivateKey=
#JobCredentialPublicCertificate=
StateSaveLocation=/var/spool/slurm/ctld
SlurmdSpoolDir=/var/spool/slurm/d
SwitchType=switch/none
MpiDefault=none
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid
ProctrackType=proctrack/cgroup
#PluginDir=
#FirstJobId=
ReturnToService=2
#MaxJobCount=
#PlugStackConfig=
#PropagatePrioProcess=
#PropagateResourceLimits=
#PropagateResourceLimitsExcept=
#Prolog=
#Epilog=
#SrunProlog=
#SrunEpilog=
#TaskProlog=
#TaskEpilog=
TaskPlugin=task/cgroup,task/affinity
#TrackWCKey=no
#TreeWidth=50
#TmpFS=
#UsePAM=
#
# TIMERS
SlurmctldTimeout=300
SlurmdTimeout=300
InactiveLimit=0
MinJobAge=300
KillWait=30
Waittime=0
#
# SCHEDULING
SchedulerType=sched/backfill
#SchedulerAuth=
SelectType=select/cons_tres
SelectTypeParameters=CR_Core
#PriorityType=priority/multifactor
#PriorityDecayHalfLife=14-0
#PriorityUsageResetPeriod=14-0
#PriorityWeightFairshare=100000
#PriorityWeightAge=1000
#PriorityWeightPartition=10000
#PriorityWeightJobSize=1000
#PriorityMaxAge=1-0
#
# LOGGING
SlurmctldDebug=debug
SlurmctldLogFile=/var/log/slurmctld.log
SlurmdDebug=debug
SlurmdLogFile=/var/log/slurmd.log
JobCompType=jobcomp/none
#JobCompLoc=
#
# ACCOUNTING
JobAcctGatherType=jobacct_gather/linux
#JobAcctGatherFrequency=30
#
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageEnforce=limits,nojobs,nosteps,qos
#AccountingStorageHost=
#AccountingStorageLoc=
#AccountingStoragePass=
#AccountingStorageUser=
#
# COMPUTE NODES
GresTypes=gpu
#NodeName=hades[03-07] State=UNKNOWN Gres=gpu:2
NodeName=hades03 State=UNKNOWN Gres=gpu:2 RealMemory=60000 Sockets=1 CoresPerSocket=6 ThreadsPerCore=2
NodeName=hades[04-05] State=UNKNOWN Gres=gpu:2 RealMemory=60000 Sockets=1 CoresPerSocket=4 ThreadsPerCore=1
NodeName=hades[06-07] State=UNKNOWN Gres=gpu:2 RealMemory=60000 Sockets=1 CoresPerSocket=4 ThreadsPerCore=2

# PartitionName=pp Nodes=ALL Default=YES MaxTime=5:00 State=UP

# PP20 partitions
#PartitionName=pp20 Nodes=hades[03-07] Default=YES MaxTime=5:00 State=UP PriorityJobFactor=1 PriorityTier=1 OverSubscribe=NO QoS=normal AllowGroups=pp20
# Partition which can use more function about nvprof
#PartitionName=prof Nodes=hades[05-07] MaxTime=5:00 State=UP PriorityJobFactor=1 PriorityTier=1 OverSubscribe=NO QoS=normal AllowGroups=pp20,ta

# PP21 partitions
PartitionName=pp21 Nodes=hades[03-07] Default=YES MaxTime=5:00 State=UP PriorityJobFactor=1 PriorityTier=1 OverSubscribe=NO QoS=normal AllowGroups=pp21st
# Partition which can use more function about nvprof
PartitionName=prof Nodes=hades[05-07] MaxTime=5:00 State=UP PriorityJobFactor=1 PriorityTier=1 OverSubscribe=NO QoS=normal AllowGroups=pp21st,ta

# IPC21 partitions
#PartitionName=ipc21 Nodes=hades[03-07] Default=YES MaxTime=15:00 State=UP PriorityJobFactor=1 PriorityTier=1 OverSubscribe=NO QoS=normal AllowGroups=ipc21
#PartitionName=prof Nodes=hades[05-07] MaxTime=5:00 State=UP PriorityJobFactor=1 PriorityTier=1 OverSubscribe=NO QoS=normal AllowGroups=ipc21,ta

PartitionName=ta Nodes=ALL MaxTime=5:00 State=UP PriorityTier=10 OverSubscribe=NO QoS=normal AllowGroups=ta
#PartitionName=elsalab Nodes=hades[07] MaxTime=2:00:00 State=UP PriorityJobFactor=1 PriorityTier=1 OverSubscribe=YES QoS=normal AllowGroups=elsalab
